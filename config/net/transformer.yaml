_target_: src.networks.TransformerEncoder
dim_in: ???
dim_out: ???
dim_cond: null
hidden_channels: 48
num_blocks: 2
num_heads: 4
mlp_ratio: 4
checkpoint_grads: false
drop_attn: 0
drop_proj: 0
drop_mlp: 0
bayesian: false
use_jvp: false
head:
  _target_: src.networks.MLP
  dim_in: ${net.hidden_channels}
  dim_out: ${net.dim_out}
  hidden_channels: ${net.hidden_channels}
  num_hidden_layers: 1
  act: silu
  out_act: null
  drop: 0
  bayesian: false
  bayesian_prior_prec: 1.0
  # init_gain: 1.0 # only used if ensembling
  # out_bias_gain: 1.0 # only used if ensembling
  ensembled: null
  layernorms: false